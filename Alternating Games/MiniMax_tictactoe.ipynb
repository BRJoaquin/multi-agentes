{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from games.tictactoe import TicTacToe\n",
    "from games.kuhn import KuhnPoker\n",
    "from agents.agent_random import RandomAgent\n",
    "from agents.counterfactualregret import CounterFactualRegret\n",
    "from agents.minimax import MiniMax\n",
    "from base.utils import play, run\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = KuhnPoker(render_mode='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfr_agent = CounterFactualRegret(game=game, agent=game.agents[0])\n",
    "random_agent = RandomAgent(game=game, agent=game.agents[1])\n",
    "# agents: dict[AgentID, Agent]\n",
    "agents = {game.agents[0]: cfr_agent, game.agents[1]: random_agent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20362/100000 [00:34<02:13, 594.89it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/k/Documents/facultad/multi-agentes/Alternating Games/MiniMax_tictactoe.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/k/Documents/facultad/multi-agentes/Alternating%20Games/MiniMax_tictactoe.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m cfr_agent\u001b[39m.\u001b[39mtrain(\u001b[39m100_000\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/facultad/multi-agentes/Alternating Games/agents/counterfactualregret.py:79\u001b[0m, in \u001b[0;36mCounterFactualRegret.train\u001b[0;34m(self, niter)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, niter\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(niter)):\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfr()\n",
      "File \u001b[0;32m~/Documents/facultad/multi-agentes/Alternating Games/agents/counterfactualregret.py:86\u001b[0m, in \u001b[0;36mCounterFactualRegret.cfr\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m game\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     85\u001b[0m probability \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones(game\u001b[39m.\u001b[39mnum_agents)\n\u001b[0;32m---> 86\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfr_rec(game\u001b[39m=\u001b[39mgame, agent\u001b[39m=\u001b[39magent, probability\u001b[39m=\u001b[39mprobability)\n",
      "File \u001b[0;32m~/Documents/facultad/multi-agentes/Alternating Games/agents/counterfactualregret.py:135\u001b[0m, in \u001b[0;36mCounterFactualRegret.cfr_rec\u001b[0;34m(self, game, agent, probability)\u001b[0m\n\u001b[1;32m    132\u001b[0m     game_clone \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    133\u001b[0m     game_clone\u001b[39m.\u001b[39mstep(a)\n\u001b[0;32m--> 135\u001b[0m     utility[a] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfr_rec(\n\u001b[1;32m    136\u001b[0m         game\u001b[39m=\u001b[39mgame_clone, agent\u001b[39m=\u001b[39magent, probability\u001b[39m=\u001b[39mnode_probability\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    139\u001b[0m node_utility \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(utility \u001b[39m*\u001b[39m node\u001b[39m.\u001b[39mpolicy())\n\u001b[1;32m    141\u001b[0m \u001b[39m# update node cumulative regrets using regret matching\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m# we only update the regrets of the agent that is building the strategy\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/facultad/multi-agentes/Alternating Games/agents/counterfactualregret.py:135\u001b[0m, in \u001b[0;36mCounterFactualRegret.cfr_rec\u001b[0;34m(self, game, agent, probability)\u001b[0m\n\u001b[1;32m    132\u001b[0m     game_clone \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    133\u001b[0m     game_clone\u001b[39m.\u001b[39mstep(a)\n\u001b[0;32m--> 135\u001b[0m     utility[a] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfr_rec(\n\u001b[1;32m    136\u001b[0m         game\u001b[39m=\u001b[39mgame_clone, agent\u001b[39m=\u001b[39magent, probability\u001b[39m=\u001b[39mnode_probability\n\u001b[1;32m    137\u001b[0m     )\n\u001b[1;32m    139\u001b[0m node_utility \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum(utility \u001b[39m*\u001b[39m node\u001b[39m.\u001b[39mpolicy())\n\u001b[1;32m    141\u001b[0m \u001b[39m# update node cumulative regrets using regret matching\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[39m# we only update the regrets of the agent that is building the strategy\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/facultad/multi-agentes/Alternating Games/agents/counterfactualregret.py:132\u001b[0m, in \u001b[0;36mCounterFactualRegret.cfr_rec\u001b[0;34m(self, game, agent, probability)\u001b[0m\n\u001b[1;32m    130\u001b[0m node_probability[game\u001b[39m.\u001b[39magent_name_mapping[current_agent]] \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m node\u001b[39m.\u001b[39mpolicy()[a]\n\u001b[1;32m    131\u001b[0m \u001b[39m# play action a\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m game_clone \u001b[39m=\u001b[39m game\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    133\u001b[0m game_clone\u001b[39m.\u001b[39mstep(a)\n\u001b[1;32m    135\u001b[0m utility[a] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfr_rec(\n\u001b[1;32m    136\u001b[0m     game\u001b[39m=\u001b[39mgame_clone, agent\u001b[39m=\u001b[39magent, probability\u001b[39m=\u001b[39mnode_probability\n\u001b[1;32m    137\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/facultad/multi-agentes/Alternating Games/base/game.py:40\u001b[0m, in \u001b[0;36mAlternatingGame.clone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclone\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 40\u001b[0m     game \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mdeepcopy(\u001b[39mself\u001b[39m)\n\u001b[1;32m     41\u001b[0m     \u001b[39mreturn\u001b[39;00m game\n",
      "File \u001b[0;32m~/anaconda3/envs/multi-agentes/lib/python3.11/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/anaconda3/envs/multi-agentes/lib/python3.11/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/anaconda3/envs/multi-agentes/lib/python3.11/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/multi-agentes/lib/python3.11/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/envs/multi-agentes/lib/python3.11/copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 y \u001b[39m=\u001b[39m x\n\u001b[1;32m    171\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m                 y \u001b[39m=\u001b[39m _reconstruct(x, memo, \u001b[39m*\u001b[39mrv)\n\u001b[1;32m    174\u001b[0m \u001b[39m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m x:\n",
      "File \u001b[0;32m~/anaconda3/envs/multi-agentes/lib/python3.11/copy.py:271\u001b[0m, in \u001b[0;36m_reconstruct\u001b[0;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[39mif\u001b[39;00m deep:\n\u001b[0;32m--> 271\u001b[0m         state \u001b[39m=\u001b[39m deepcopy(state, memo)\n\u001b[1;32m    272\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(y, \u001b[39m'\u001b[39m\u001b[39m__setstate__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    273\u001b[0m         y\u001b[39m.\u001b[39m__setstate__(state)\n",
      "File \u001b[0;32m~/anaconda3/envs/multi-agentes/lib/python3.11/copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m copier \u001b[39m=\u001b[39m _deepcopy_dispatch\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    145\u001b[0m \u001b[39mif\u001b[39;00m copier \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 146\u001b[0m     y \u001b[39m=\u001b[39m copier(x, memo)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(\u001b[39mcls\u001b[39m, \u001b[39mtype\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/multi-agentes/lib/python3.11/copy.py:231\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    229\u001b[0m memo[\u001b[39mid\u001b[39m(x)] \u001b[39m=\u001b[39m y\n\u001b[1;32m    230\u001b[0m \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m x\u001b[39m.\u001b[39mitems():\n\u001b[0;32m--> 231\u001b[0m     y[deepcopy(key, memo)] \u001b[39m=\u001b[39m deepcopy(value, memo)\n\u001b[1;32m    232\u001b[0m \u001b[39mreturn\u001b[39;00m y\n",
      "File \u001b[0;32m~/anaconda3/envs/multi-agentes/lib/python3.11/copy.py:155\u001b[0m, in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    153\u001b[0m     y \u001b[39m=\u001b[39m copier(memo)\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     reductor \u001b[39m=\u001b[39m dispatch_table\u001b[39m.\u001b[39mget(\u001b[39mcls\u001b[39m)\n\u001b[1;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m reductor:\n\u001b[1;32m    157\u001b[0m         rv \u001b[39m=\u001b[39m reductor(x)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cfr_agent.train(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t agent_0\t [0.99836767 0.00163233]\n",
      "0b\t agent_1\t [9.99852027e-01 1.47972773e-04]\n",
      "0p\t agent_1\t [0.99698627 0.00301373]\n",
      "0pb\t agent_0\t [9.99849760e-01 1.50240385e-04]\n",
      "1\t agent_0\t [0.99772481 0.00227519]\n",
      "1b\t agent_1\t [0.41101095 0.58898905]\n",
      "1p\t agent_1\t [9.99844817e-01 1.55183116e-04]\n",
      "1pb\t agent_0\t [5.36634616e-04 9.99463365e-01]\n",
      "2\t agent_0\t [0.00529859 0.99470141]\n",
      "2b\t agent_1\t [1.46972369e-04 9.99853028e-01]\n",
      "2p\t agent_1\t [1.46972369e-04 9.99853028e-01]\n",
      "2pb\t agent_0\t [1.48986889e-04 9.99851013e-01]\n"
     ]
    }
   ],
   "source": [
    "for n in sorted(cfr_agent.node_dict.keys()): \n",
    "    print(n + '\\t', cfr_agent.node_dict[n].agent + '\\t', cfr_agent.node_dict[n].policy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Train agent before calling action()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/facultad/multi-agentes/Alternating Games/agents/counterfactualregret.py:68\u001b[0m, in \u001b[0;36mCounterFactualRegret.action\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 68\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_dict[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgame\u001b[39m.\u001b[39mobserve(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent)]\n\u001b[1;32m     69\u001b[0m     a \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mmultinomial(\u001b[39m1\u001b[39m, node\u001b[39m.\u001b[39mpolicy(), size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: '2'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/k/Documents/facultad/multi-agentes/Alternating Games/MiniMax_tictactoe.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/k/Documents/facultad/multi-agentes/Alternating%20Games/MiniMax_tictactoe.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m run(game\u001b[39m=\u001b[39mgame, agents\u001b[39m=\u001b[39magents, N\u001b[39m=\u001b[39m\u001b[39m10_000\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/facultad/multi-agentes/Alternating Games/base/utils.py:19\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(game, agents, N)\u001b[0m\n\u001b[1;32m     17\u001b[0m game\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     18\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m game\u001b[39m.\u001b[39mterminated():\n\u001b[0;32m---> 19\u001b[0m     action \u001b[39m=\u001b[39m agents[game\u001b[39m.\u001b[39magent_selection]\u001b[39m.\u001b[39maction()\n\u001b[1;32m     20\u001b[0m     game\u001b[39m.\u001b[39mstep(action)\n\u001b[1;32m     21\u001b[0m values\u001b[39m.\u001b[39mappend(game\u001b[39m.\u001b[39mreward(game\u001b[39m.\u001b[39magents[\u001b[39m0\u001b[39m]))\n",
      "File \u001b[0;32m~/Documents/facultad/multi-agentes/Alternating Games/agents/counterfactualregret.py:72\u001b[0m, in \u001b[0;36mCounterFactualRegret.action\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[39mreturn\u001b[39;00m a\n\u001b[1;32m     71\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTrain agent before calling action()\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Train agent before calling action()"
     ]
    }
   ],
   "source": [
    "run(game=game, agents=agents, N=10_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agents[game.agents[1]] = MiniMax(game=game, agent=game.agents[1], depth=2)\n",
    "# run(game=game, agents=agents, N=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
